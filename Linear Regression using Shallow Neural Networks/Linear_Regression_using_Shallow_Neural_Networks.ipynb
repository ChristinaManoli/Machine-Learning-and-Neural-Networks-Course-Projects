{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Εργασία 1**\n",
        "\n",
        "Παλινδρόμηση με νευρωνικά δίκτυα και το climate change dataset."
      ],
      "metadata": {
        "id": "seu95T5hvb_I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Φόρτωση και προεργασία\n",
        "\n",
        "Φόρτωση βιβλιοθηκών, φόρτωση και απεικόνιση δεδομένων"
      ],
      "metadata": {
        "id": "iIJJzcqWvyeg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDk2kAq9s-9Y"
      },
      "outputs": [],
      "source": [
        "# Εισάγουμε όλες τις απαραίτητες βιβλιοθήκες\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Φορτώνουμε το αρχείο CSV με τη βιβλιοθήκη Pandas μόνο για λόγους απεικόνισης\n",
        "dataframe = pd.read_csv('climate_change.csv')\n",
        "print(dataframe.head(5))\n",
        "print(\"Διαστάσεις:\", dataframe.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgvJhpZFIGlT",
        "outputId": "f7cc6902-597f-41cb-8db8-be144976724a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Year  Month    MEI     CO2      CH4      N2O   CFC-11   CFC-12        TSI  \\\n",
            "0  1983      5  2.556  345.96  1638.59  303.677  191.324  350.113  1366.1024   \n",
            "1  1983      6  2.167  345.52  1633.71  303.746  192.057  351.848  1366.1208   \n",
            "2  1983      7  1.741  344.15  1633.22  303.795  192.818  353.725  1366.2850   \n",
            "3  1983      8  1.130  342.25  1631.35  303.839  193.602  355.633  1366.4202   \n",
            "4  1983      9  0.428  340.17  1648.40  303.901  194.392  357.465  1366.2335   \n",
            "\n",
            "   Aerosols   Temp  \n",
            "0    0.0863  0.109  \n",
            "1    0.0794  0.118  \n",
            "2    0.0731  0.137  \n",
            "3    0.0673  0.176  \n",
            "4    0.0619  0.149  \n",
            "Διαστάσεις: (308, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Δημιουργία custom αντικειμένου Dataset\n",
        "\n",
        "Δημιουργούμε ένα αντικείμενο Dataset το οποίο θα τροφοδοτήσει τους dataloaders, και ένα αντικείμενο transform που θα τροποποιεί τα δεδομένα πριν διαβαστούν από τους loaders.\n",
        "\n",
        "Στο μέλλον το transform θα είναι πολύ σημαντικό για το data augmentation, αλλά για την ώρα το χρησιμοποιούμε για την κανονικοποίηση των δεδομένων."
      ],
      "metadata": {
        "id": "Fd9abT0PwEbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ClimateDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, csv_file, transform=None, train=True):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      csv_file (string): Path to the csv file\n",
        "      transform (callable, optional): Optional transform to be applied\n",
        "          on each sample.\n",
        "      train (bool): whether to create the training set or the test set\n",
        "    \"\"\"\n",
        "\n",
        "    # Ορίζουμε το μέγεθος του training set\n",
        "    train_set_size = 250\n",
        "\n",
        "    # Φόρτωση του csv μέσω Pandas, διαγραφή στηλών που δε βοηθούν στην ανάλυση,\n",
        "    # μετατροπή των Pandas Dataframes σε Numpy Arrays, που έχουν πιο βοηθητικές\n",
        "    # ιδιότητες\n",
        "    dataframe = pd.read_csv(csv_file)\n",
        "    targets = np.array(dataframe[['Temp']]).astype('float32')\n",
        "    data = np.array(dataframe.drop(columns=['Year','Month','Temp'])).astype('float32')\n",
        "\n",
        "    # Διαχωρισμός των δεδομένων σε training και test set\n",
        "    # Αυτή η γραμμή θα πρέπει στο μέλλον να αντικατασταθεί αν θέλουμε να κάνουμε \n",
        "    # πιο ρεαλιστική αξιολόγηση\n",
        "    # Θέτουμε και το seed στο random state για λόγους επαναληψιμότητας\n",
        "    train_data, test_data, train_targets, test_targets = train_test_split(data, \n",
        "                            targets, train_size=train_set_size, random_state=665)\n",
        "\n",
        "    # Θέτουμε και αρχικοποιούμε το transform\n",
        "    self.transform = transform\n",
        "    # Προσοχή, το transform αρχικοποιείται με τις τιμές του training set, είτε\n",
        "    # το Dataset αφορά το train είτε το test set.\n",
        "    self.transform.fit(train_data, train_targets)\n",
        "\n",
        "    # Αν μας έχει ζητηθεί να δημιουργηθεί train database, κρατάμε τα train data.\n",
        "    # Αλλιώς κρατάμε τα test data. \n",
        "    if train==True:\n",
        "      self.data = train_data\n",
        "      self.targets = train_targets\n",
        "    else:\n",
        "      self.data = test_data\n",
        "      self.targets = test_targets\n",
        "    # Η αρχικοποίηση τελειώνει εδώ\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # Ή __len__ ενός αντικειμένου Dataset οφείλει να επιστρέφει το πλήθος των\n",
        "  # αντικειμένων του.\n",
        "  def __len__(self):\n",
        "    return len(self.targets)\n",
        "\n",
        "  # Η __getitem__ ενός αντικειμένου Dataset παίρνει ως παράμετρο ένα index και \n",
        "  # επιστρέφει το αντίστοιχο αντικείμενο. Τη χρησιμοποιεί ο DataLoader για να \n",
        "  # αντλεί minibatches.\n",
        "  def __getitem__(self, idx):\n",
        "    if torch.is_tensor(idx):\n",
        "      idx = idx.tolist()\n",
        "    item_data = self.data[idx,:]\n",
        "    item_target = self.targets[idx,:]\n",
        "    \n",
        "    # Αν έχουμε ορίσει transform, το εφαρμόζουμε στο αντικείμενο πριν το \n",
        "    # επιστρέψουμε. Όταν καλώ το transform με το όνομά του, στην πραγματικότητα\n",
        "    # καλείται η transform.__call__() (βλ. παρακάτω)\n",
        "    if self.transform:\n",
        "      item_data, item_target = self.transform(item_data, item_target)\n",
        "    return item_data, item_target\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Η κλάση αυτή θα παίξει το ρόλο του Transform. Θα αφαιρεί την ελάχιστη τιμή\n",
        "# από κάθε στήλη των δεδομένων και θα διαιρεί με το φάσμα της, ώστε να κανονικοποιεί\n",
        "# τις τιμές όλων των μεταβλητών (και των στόχων) στο [0,1]\n",
        "class MinMaxScaler():\n",
        "\n",
        "  # H fit αρχικοποιείται με τα training data, και υπολογίζει τις ελάχιστες και \n",
        "  # μέγιστες τιμές. Τα αντικείμενα είναι numpy arrays, οπότε έχουν ενσωματωμένη\n",
        "  # τη συνάρτηση min και max \n",
        "  def fit(self, data, targets):\n",
        "    self.data_min = data.min(0, keepdims=True)\n",
        "    self.target_min = targets.min(0, keepdims=True)\n",
        "    self.data_max = data.max(0, keepdims=True)\n",
        "    self.target_max = targets.max(0, keepdims=True)\n",
        "    return self\n",
        "\n",
        "  # Όταν καλείται η transform.__call__(), δέχεται ένα αντικείμενο (data και target)\n",
        "  # και το επιστρέφει μετασχηματισμένο -εν προκειμένω κανονικοποιημένο\n",
        "  def __call__(self, data, target):\n",
        "    data = (data - self.data_min)/(self.data_max-self.data_min)\n",
        "    target = (target - self.target_min)/(self.target_max-self.target_min)\n",
        "    return data, target\n",
        "\n",
        "  # Θα εκπαιδεύσουμε ένα σύστημα να μαθαίνει τα κανονικοποιημένα targets. Για\n",
        "  # εφαρμογή στον πραγματικό κόσμο, θα χρειαστεί να μπορούμε να μετασχηματίζουμε\n",
        "  # τα outputs του συστήματος πίσω στο αρχικό φάσμα τιμών του\n",
        "  def inverse_transform(self, data, target):\n",
        "    data=data * (self.data_max-self.data_min) + self.data_min\n",
        "    target = target * (self.target_max-self.target_min) + self.target_min\n",
        "    return data, target"
      ],
      "metadata": {
        "id": "1y_r_4ngKxAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Δημιουργία DataLoaders\n",
        "\n",
        "Δημιουργούμε dataloaders για το training set και για το test set."
      ],
      "metadata": {
        "id": "SUa7z3yH0t5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To batch size είναι αρκετά μεγάλο ώστε να χωράει όλα τα training data και όλα \n",
        "# τα test data σε ένα loop (πρακτικά εφαρμόζουμε Batch Gradient Descent, κάθε\n",
        "# Batch είναι ένα Epoch) \n",
        "# (αν το batch size είναι μεγαλύτερο από τα διαθέσιμα δεδομένα, η pytorch \n",
        "# δημιουργεί ένα batch με τα διαθέσιμα δεδομένα)\n",
        "batch_size = 500\n",
        "transform=MinMaxScaler()\n",
        "\n",
        "train_dataset = ClimateDataset(csv_file='climate_change.csv', train=True, transform=transform)\n",
        "test_dataset = ClimateDataset(csv_file='climate_change.csv', train=False, transform=transform)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "YQmvU0I50tBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Αρχιτεκτονική δικτύου\n",
        "\n",
        "Ορίζουμε ένα απλό δίκτυο με έναν νευρώνα για γραμμική παλινδρόμηση"
      ],
      "metadata": {
        "id": "doGIwzMX1FP3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Κώδικας ορισμού του δικτύου\n",
        "class NeuralNetwork1(nn.Module):\n",
        "  def __init__(self):\n",
        "    # Τρέχω την init της κλάσης-γονιού\n",
        "    super(NeuralNetwork1, self).__init__()\n",
        "    \n",
        "    #Δημιουργώ μια αρχιτεκτονική που θα αποτελείται αποκλειστικά από έναν νευρώνα με γραμμική συνάρτηση ενεργοποίησης.\n",
        "    self.network_architecture = nn.Sequential(\n",
        "        nn.Linear(8, 1),\n",
        "        #Το input 𝐱 του δικτύου αποτελειται απο 8 μεταβλητες, καθως κατα την προεργασία από την κλάση ClimateDataset αφαιρεσαμε τα targets, 'Temp', και τις στηλες 'Year' και 'Month'.\n",
        "        )\n",
        "    \n",
        "  def forward(self, x):\n",
        "    logits = self.network_architecture(x)\n",
        "    return logits"
      ],
      "metadata": {
        "id": "SWZzmPr01XuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training και Test Loop\n",
        "\n",
        "Γράφουμε τον κώδικα του training loop και του test loop"
      ],
      "metadata": {
        "id": "CSZJ-_-K1YRI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer, display):\n",
        "    size = len(dataloader.dataset)\n",
        "    \n",
        "    \n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "      # Κάθε batch έχει διαστάσεις [250, 1, 8]\n",
        "      # Compute prediction and loss\n",
        "      pred = model(X)\n",
        "      loss = loss_fn(pred, y)\n",
        "\n",
        "      # Backpropagation\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      if display % 100 == 0:\n",
        "        loss, current = loss.item(), len(X)\n",
        "        print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "    TheTargets = []\n",
        "    ThePredictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "  \n",
        "    for i in y:\n",
        "      TheTargets.append(i.item())\n",
        "    \n",
        "    for j in pred:\n",
        "      ThePredictions.append(j.item())\n",
        "\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "  \n",
        "    print(f\"Test Error: \\n R2 Score: {r2_score(TheTargets, ThePredictions)} , Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "ffBgVWDpbVef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Συνάρτηση κόστους (Loss Function)"
      ],
      "metadata": {
        "id": "AWkrWGr5lZTE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ορίζουμε ως Loss Function την MSELoss() (Μέσο Τετραγωνικό Σφάλμα) καθώς ειναι κατάλληλη για προβληματα παλινδρόμησης.\n",
        "loss_fn = nn.MSELoss()"
      ],
      "metadata": {
        "id": "2gIf_sxrlszS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ορισμός υπερπαραμέτρων και εκπαίδευση δικτύου\n",
        "\n",
        "Κώδικας εκτέλεσης και αξιολόγησης του δικτύου "
      ],
      "metadata": {
        "id": "RF_TfBa89VF4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Το manual_seed καθορίζει την τυχαία αρχικοποίηση των βαρών/παραμέτρων του δικτύου\n",
        "# Πρόκειται απλώς για ένα σταθερό seed στο random number generator της pytorch.\n",
        "torch.manual_seed(100)\n",
        "#torch.manual_seed(50)\n",
        "\n",
        "model = NeuralNetwork1()\n",
        "learning_rate = 0.001\n",
        "epochs = 3000\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Κώδικας εκπαίδευσης εδώ:\n",
        "for t in range(epochs):\n",
        "    if t % 100 == 0:\n",
        "      print(f\"Epoch {t}\\n-------------------------------\")\n",
        "    train_loop(train_dataloader, model, loss_fn, optimizer, t)\n",
        "    if t % 100 == 0:\n",
        "      test_loop(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "id": "f1beitvisMNY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78a506fb-fd9f-4fc7-ab6d-8bb7886a61a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n",
            "-------------------------------\n",
            "loss: 0.532136  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -25.27130098504746 , Avg loss: 0.551750 \n",
            "\n",
            "Epoch 100\n",
            "-------------------------------\n",
            "loss: 0.162329  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -6.7977772675125765 , Avg loss: 0.163769 \n",
            "\n",
            "Epoch 200\n",
            "-------------------------------\n",
            "loss: 0.068843  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -2.2233631332819366 , Avg loss: 0.067697 \n",
            "\n",
            "Epoch 300\n",
            "-------------------------------\n",
            "loss: 0.044570  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -1.0770251520030025 , Avg loss: 0.043622 \n",
            "\n",
            "Epoch 400\n",
            "-------------------------------\n",
            "loss: 0.037668  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -0.7669670089043794 , Avg loss: 0.037110 \n",
            "\n",
            "Epoch 500\n",
            "-------------------------------\n",
            "loss: 0.035157  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -0.6576277124832313 , Avg loss: 0.034813 \n",
            "\n",
            "Epoch 600\n",
            "-------------------------------\n",
            "loss: 0.033786  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -0.5958033873339577 , Avg loss: 0.033515 \n",
            "\n",
            "Epoch 700\n",
            "-------------------------------\n",
            "loss: 0.032740  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -0.5457179761920823 , Avg loss: 0.032463 \n",
            "\n",
            "Epoch 800\n",
            "-------------------------------\n",
            "loss: 0.031811  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -0.49949994500604467 , Avg loss: 0.031492 \n",
            "\n",
            "Epoch 900\n",
            "-------------------------------\n",
            "loss: 0.030945  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -0.45559646126668496 , Avg loss: 0.030570 \n",
            "\n",
            "Epoch 1000\n",
            "-------------------------------\n",
            "loss: 0.030128  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -0.4137473678410333 , Avg loss: 0.029692 \n",
            "\n",
            "Epoch 1100\n",
            "-------------------------------\n",
            "loss: 0.029354  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -0.3738906618494142 , Avg loss: 0.028854 \n",
            "\n",
            "Epoch 1200\n",
            "-------------------------------\n",
            "loss: 0.028619  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -0.3359642905459408 , Avg loss: 0.028058 \n",
            "\n",
            "Epoch 1300\n",
            "-------------------------------\n",
            "loss: 0.027922  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -0.2998867399881162 , Avg loss: 0.027300 \n",
            "\n",
            "Epoch 1400\n",
            "-------------------------------\n",
            "loss: 0.027259  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -0.2655664372968287 , Avg loss: 0.026579 \n",
            "\n",
            "Epoch 1500\n",
            "-------------------------------\n",
            "loss: 0.026630  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -0.2329104557381554 , Avg loss: 0.025894 \n",
            "\n",
            "Epoch 1600\n",
            "-------------------------------\n",
            "loss: 0.026031  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -0.20182900151120875 , Avg loss: 0.025241 \n",
            "\n",
            "Epoch 1700\n",
            "-------------------------------\n",
            "loss: 0.025462  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -0.1722343737268781 , Avg loss: 0.024619 \n",
            "\n",
            "Epoch 1800\n",
            "-------------------------------\n",
            "loss: 0.024921  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -0.1440447210020226 , Avg loss: 0.024027 \n",
            "\n",
            "Epoch 1900\n",
            "-------------------------------\n",
            "loss: 0.024406  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -0.11718236977530316 , Avg loss: 0.023463 \n",
            "\n",
            "Epoch 2000\n",
            "-------------------------------\n",
            "loss: 0.023916  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -0.09157474144168254 , Avg loss: 0.022925 \n",
            "\n",
            "Epoch 2100\n",
            "-------------------------------\n",
            "loss: 0.023449  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -0.06715276105289125 , Avg loss: 0.022412 \n",
            "\n",
            "Epoch 2200\n",
            "-------------------------------\n",
            "loss: 0.023004  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -0.043852030264690534 , Avg loss: 0.021923 \n",
            "\n",
            "Epoch 2300\n",
            "-------------------------------\n",
            "loss: 0.022580  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -0.0216114736130939 , Avg loss: 0.021456 \n",
            "\n",
            "Epoch 2400\n",
            "-------------------------------\n",
            "loss: 0.022176  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -0.00037365743105377547 , Avg loss: 0.021010 \n",
            "\n",
            "Epoch 2500\n",
            "-------------------------------\n",
            "loss: 0.021791  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.019915893676952234 , Avg loss: 0.020584 \n",
            "\n",
            "Epoch 2600\n",
            "-------------------------------\n",
            "loss: 0.021423  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.03930812753334534 , Avg loss: 0.020176 \n",
            "\n",
            "Epoch 2700\n",
            "-------------------------------\n",
            "loss: 0.021071  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.05785126016297204 , Avg loss: 0.019787 \n",
            "\n",
            "Epoch 2800\n",
            "-------------------------------\n",
            "loss: 0.020736  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.07559023779081187 , Avg loss: 0.019414 \n",
            "\n",
            "Epoch 2900\n",
            "-------------------------------\n",
            "loss: 0.020415  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.09256793853624656 , Avg loss: 0.019058 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Τι παρατηρείτε να συμβαίνει στα train/test loss και στο R2 score καθώς περνάνε τα Epochs;\n",
        "\n",
        "Απάντηση: Καθώς περνάνε τα Epochs μπορουμε να παρατηρήσουμε ότι όσον αφορά το train Loss αυτό μειώνεται συνεχως, ξεκινώντας απο το 1ο epoch βλεπουμε οτι το Loss ειναι 0.532136 και στην συνεχεια παρουσιάζει μεγάλη μείωση μέχρι να φτασει στο 0.029354 και να καταληξει στο 0.020415.\n",
        "\n",
        "Όσον αφορα το test Loss μπορούμε να παρατήρησουμε ότι και αυτο μειώνεται σταδιακά παρουσιάζοντας μεγάλη μειωση στα πρώτα 400 epochs ωσπου να καταλήξει στο 0.019058.\n",
        "\n",
        "Το R2 score παρατηρούμε ότι και αυτο αυξάνεται. Έχοντας αρχικά αρνητικές τιμές (<0) πράγμα που σημαίνει ότι το μοντελο δεν είναι αρκετα καλό.\n",
        "Μετά απο 2500 epochs παρατηρούμε ότι η τιμή του R2 Score ειναι πλέον μεγαλύτερη του 0. Τελος, έχοντας R2 Score: **0.09256793853624656**, συμπεραίνουμε ότι το ποσοστό της διασποράς των δεδομένων που εκφράζεται σωστά από το μοντέλο ειναι αρκετα μικρό καθως φτανει μολις στο 0.09  "
      ],
      "metadata": {
        "id": "Dv_ER0oIsgqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Τι παρατηρείτε σε σχέση με τις τιμές των μετρικών στο χρόνο; Τι μπορείτε να συμπεράνετε από αυτό;\n",
        "\n",
        "Απάντηση:\n",
        "> Για torch.manual_seed(100): Ισχύει ότι προανέφερα παραπάνω για τα train/test loss και R2 Score. Συμπαιρένουμε ότι οι τιμές των μετρικών μειώνονται στην δειάρκεια του χρόνου με ιδιαίτερη μεταβολή στην αρχη καθως τα weights απο random που ειναι αρχικα μετα αρχίζουν σταδιακα να βελτιώνονται.\n",
        "\n",
        "\n",
        "\n",
        "> Για torch.manual_seed(50): Παρατηρούμε ότι οι τιμές των μετρικών train, test Loss και R2 Score συνεχώς μειώνονται.Επιπλέον, η βελτίωση των τιμών σε σχεση με πριν ειναι μεγαλύτερη. Ειδικότερα το R2 Score βλεπουμε οτι εχει μεγαλυτερη βελτιωση στην τιμή του σε σχεση με πριν και αυξηση της τιμης εως και **0.31448371739472414** που ειναι συγκριτικα καλυτερη με πριν. Παρολαυτα, μπορουμε να παρατηρησδουμε επισης ότι στα πρωτα epochs οι τιμες των μετρικων ειναι αρκετα χειροότερες σε σχέση με πριν.\n"
      ],
      "metadata": {
        "id": "nv6qb1Gwsz1D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Optimizer: Adam** \n",
        "### Τι παρατηρείτε για την εκπαίδευση του δικτύου;\n",
        "\n",
        "Απάντηση: Έχοντας εφαρμόσει ως Adam optimizer αντι για SGD παρατηρούμε, με βάση τις τιμες των μετρικων, ότι η εκπαιδευση του δικτύου βελτιώθηκε αρκετά καθώς οι τιμες και των τρειων μετρικων από epoch σε epoch βελτιώνονται ραγδαια με αποτελεσμα να έχουμε στο τελος **Train Loss: 0.009197, Avg loss: 0.007105 και R2 Score: 0.6616853195249721** που είναι μια αρκετα καλή τιμή πάνω απο το 0.5 που πλησιάζει το 1."
      ],
      "metadata": {
        "id": "sCUkCQn0s8b5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Νευρωνικό δίκτυο"
      ],
      "metadata": {
        "id": "08tb4Oe7pZX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Κώδικας ορισμού του δικτύου\n",
        "class NeuralNetwork2(nn.Module):\n",
        "  def __init__(self):\n",
        "    # Τρέχω την init της κλάσης-γονιού\n",
        "    super(NeuralNetwork2, self).__init__()\n",
        "    \n",
        "    #Δημιουργώ μια αρχιτεκτονική που θα αποτελείται αποκλειστικά από έναν νευρώνα με γραμμική συνάρτηση ενεργοποίησης.\n",
        "    self.network_architecture = nn.Sequential(\n",
        "        nn.Linear(8, 100),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(100, 100),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(100, 1),\n",
        "        #η έξοδος του δικτύου είναι μη γραμμική συνάρτηση των αρχικων εισόδων (του δικτύου), καθώς όλοι οι κρυφοί νευρώνες έχουν μη γραμμική συνάρτηση ενεργοποίησης (ReLU).\n",
        "\n",
        "    )\n",
        "    \n",
        "  def forward(self, x):\n",
        "    logits = self.network_architecture(x)\n",
        "    return logits"
      ],
      "metadata": {
        "id": "bwBWbnN_pcTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ορισμός υπερπαραμέτρων και εκπαίδευση δικτύου"
      ],
      "metadata": {
        "id": "Pf4ct2ZFdBSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(50)\n",
        "\n",
        "model = NeuralNetwork2()\n",
        "learning_rate = 0.001\n",
        "epochs = 3000\n",
        "\n",
        "optimizer2 = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "#optimizer2 = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Κώδικας εκπαίδευσης εδώ:\n",
        "for t in range(epochs):\n",
        "    if t % 100 == 0:\n",
        "      print(f\"Epoch {t}\\n-------------------------------\")\n",
        "    train_loop(train_dataloader, model, loss_fn, optimizer2, t)\n",
        "    if t % 100 == 0:\n",
        "      test_loop(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "id": "JtnT1_vcteiQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea672bb7-0817-4a15-ead3-cc1d4c9889eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n",
            "-------------------------------\n",
            "loss: 0.382369  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -19.83784899013452 , Avg loss: 0.437636 \n",
            "\n",
            "Epoch 100\n",
            "-------------------------------\n",
            "loss: 0.088239  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -3.925405634362586 , Avg loss: 0.103443 \n",
            "\n",
            "Epoch 200\n",
            "-------------------------------\n",
            "loss: 0.029093  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -0.4570168839710582 , Avg loss: 0.030600 \n",
            "\n",
            "Epoch 300\n",
            "-------------------------------\n",
            "loss: 0.018007  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.30938529505681456 , Avg loss: 0.014504 \n",
            "\n",
            "Epoch 400\n",
            "-------------------------------\n",
            "loss: 0.016027  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.49129072559192677 , Avg loss: 0.010684 \n",
            "\n",
            "Epoch 500\n",
            "-------------------------------\n",
            "loss: 0.015555  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.5452724837616237 , Avg loss: 0.009550 \n",
            "\n",
            "Epoch 600\n",
            "-------------------------------\n",
            "loss: 0.015322  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.5669194103016943 , Avg loss: 0.009096 \n",
            "\n",
            "Epoch 700\n",
            "-------------------------------\n",
            "loss: 0.015133  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.5787266421931179 , Avg loss: 0.008848 \n",
            "\n",
            "Epoch 800\n",
            "-------------------------------\n",
            "loss: 0.014957  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.5870483831749347 , Avg loss: 0.008673 \n",
            "\n",
            "Epoch 900\n",
            "-------------------------------\n",
            "loss: 0.014792  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.5937157360919316 , Avg loss: 0.008533 \n",
            "\n",
            "Epoch 1000\n",
            "-------------------------------\n",
            "loss: 0.014635  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.5994858160264378 , Avg loss: 0.008412 \n",
            "\n",
            "Epoch 1100\n",
            "-------------------------------\n",
            "loss: 0.014486  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.6047993694534383 , Avg loss: 0.008300 \n",
            "\n",
            "Epoch 1200\n",
            "-------------------------------\n",
            "loss: 0.014346  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.6096995779812597 , Avg loss: 0.008197 \n",
            "\n",
            "Epoch 1300\n",
            "-------------------------------\n",
            "loss: 0.014214  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.6142009402292019 , Avg loss: 0.008103 \n",
            "\n",
            "Epoch 1400\n",
            "-------------------------------\n",
            "loss: 0.014091  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.6181909454905874 , Avg loss: 0.008019 \n",
            "\n",
            "Epoch 1500\n",
            "-------------------------------\n",
            "loss: 0.013977  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.6218807747257258 , Avg loss: 0.007941 \n",
            "\n",
            "Epoch 1600\n",
            "-------------------------------\n",
            "loss: 0.013872  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.6253171684078966 , Avg loss: 0.007869 \n",
            "\n",
            "Epoch 1700\n",
            "-------------------------------\n",
            "loss: 0.013772  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.6284389069255798 , Avg loss: 0.007804 \n",
            "\n",
            "Epoch 1800\n",
            "-------------------------------\n",
            "loss: 0.013675  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.6313469369987248 , Avg loss: 0.007742 \n",
            "\n",
            "Epoch 1900\n",
            "-------------------------------\n",
            "loss: 0.013582  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.6341333718225107 , Avg loss: 0.007684 \n",
            "\n",
            "Epoch 2000\n",
            "-------------------------------\n",
            "loss: 0.013493  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.6368673144101931 , Avg loss: 0.007627 \n",
            "\n",
            "Epoch 2100\n",
            "-------------------------------\n",
            "loss: 0.013407  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.6394834590885363 , Avg loss: 0.007572 \n",
            "\n",
            "Epoch 2200\n",
            "-------------------------------\n",
            "loss: 0.013323  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.6420082619724321 , Avg loss: 0.007519 \n",
            "\n",
            "Epoch 2300\n",
            "-------------------------------\n",
            "loss: 0.013244  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.6443748183140665 , Avg loss: 0.007469 \n",
            "\n",
            "Epoch 2400\n",
            "-------------------------------\n",
            "loss: 0.013168  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.6466500239761146 , Avg loss: 0.007421 \n",
            "\n",
            "Epoch 2500\n",
            "-------------------------------\n",
            "loss: 0.013095  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.6488095225905575 , Avg loss: 0.007376 \n",
            "\n",
            "Epoch 2600\n",
            "-------------------------------\n",
            "loss: 0.013026  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.6508614885235702 , Avg loss: 0.007333 \n",
            "\n",
            "Epoch 2700\n",
            "-------------------------------\n",
            "loss: 0.012959  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.6527914537789092 , Avg loss: 0.007292 \n",
            "\n",
            "Epoch 2800\n",
            "-------------------------------\n",
            "loss: 0.012896  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.6545959373064595 , Avg loss: 0.007254 \n",
            "\n",
            "Epoch 2900\n",
            "-------------------------------\n",
            "loss: 0.012835  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.6563155584689719 , Avg loss: 0.007218 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Τι παρατηρείτε σε σχέση με την ταχύτητα εκπαίδευσης, και τις τιμές των κριτηρίων αξιολόγησης στο χρόνο;\n",
        "\n",
        "Με Optimizer:\n",
        "\n",
        "> **SGD**: Παρατηρούμε ότι η ταχύτητα εκπάιδευσης του δικτύου ειναι αρκετα υψηλης σε σχεση με πριν (βλ 2. Μεμονωμένος νευρώνας) και αυτο ειναι εμφανες απο τις χαμηλες τιμες των κριτηρίων αξιολόγησης (Train/Test Loss) απο το πρωτο κιολας epoch και καθως προχωραμε απο epoch σε epoch. Μπορει επιπλεον να παρατηρησει κανεις οτι η υψηλη ταχυτητα εκπαιδευσης ειναι ιδιαιτερα εμφανης στα πρωτα 500 epoch. Επιπλεόν οι τιμες των κριτηριων αξιολογησης, **Train και Test Loss**, είναι καλυτερες σε σχεση με πριν, **0.012835 και 0.007218** αντιστοιχα. η τιμη του **R2 Score** ειναι αρκετα πιο υψηλη (**0.6563155584689719**) σε σχεση με την *προηγουμενη τιμή (0.09256793853624656).*\n",
        "\n",
        "\n",
        "> **Adam**: Παρατηρουμε ότι οπως και με τον SGD η ταχυτητα ειναι αρκετα υψηλης σε σχεση με πριν καθως και όσο περναει ο χρονος οι τιμες των κριτηρίων αξιολόγησης αυξομειωνονται συνεχως. Επιπλέον, παρατηρουμε οτι με τον Adam Optimizer, οι τιμες των κριτηρίων αξιολόγησης γνωρίζουν ραγδαια βελτίωση στα πρωτα 100 epochs. Όμως, παρατηρηθηκε ότι ενω αρχικα οι τιμή του **R2 Score** ειναι αρκετα καλή (*0.7615950507301525*) στην συνεχεια οσο περνανε τα epochs η τιμη της χειροτερευει ωσπου να καταληξει στο **0.6858477112869089**.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9VmWP-O1__jV"
      }
    }
  ]
}