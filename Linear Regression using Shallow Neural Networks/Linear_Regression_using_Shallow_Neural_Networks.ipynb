{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Î•ÏÎ³Î±ÏƒÎ¯Î± 1**\n",
        "\n",
        "Î Î±Î»Î¹Î½Î´ÏÏŒÎ¼Î·ÏƒÎ· Î¼Îµ Î½ÎµÏ…ÏÏ‰Î½Î¹ÎºÎ¬ Î´Î¯ÎºÏ„Ï…Î± ÎºÎ±Î¹ Ï„Î¿ climate change dataset."
      ],
      "metadata": {
        "id": "seu95T5hvb_I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Î¦ÏŒÏÏ„Ï‰ÏƒÎ· ÎºÎ±Î¹ Ï€ÏÎ¿ÎµÏÎ³Î±ÏƒÎ¯Î±\n",
        "\n",
        "Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Î²Î¹Î²Î»Î¹Î¿Î¸Î·ÎºÏÎ½, Ï†ÏŒÏÏ„Ï‰ÏƒÎ· ÎºÎ±Î¹ Î±Ï€ÎµÎ¹ÎºÏŒÎ½Î¹ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½"
      ],
      "metadata": {
        "id": "iIJJzcqWvyeg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDk2kAq9s-9Y"
      },
      "outputs": [],
      "source": [
        "# Î•Î¹ÏƒÎ¬Î³Î¿Ï…Î¼Îµ ÏŒÎ»ÎµÏ‚ Ï„Î¹Ï‚ Î±Ï€Î±ÏÎ±Î¯Ï„Î·Ï„ÎµÏ‚ Î²Î¹Î²Î»Î¹Î¿Î¸Î®ÎºÎµÏ‚\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Î¦Î¿ÏÏ„ÏÎ½Î¿Ï…Î¼Îµ Ï„Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ CSV Î¼Îµ Ï„Î· Î²Î¹Î²Î»Î¹Î¿Î¸Î®ÎºÎ· Pandas Î¼ÏŒÎ½Î¿ Î³Î¹Î± Î»ÏŒÎ³Î¿Ï…Ï‚ Î±Ï€ÎµÎ¹ÎºÏŒÎ½Î¹ÏƒÎ·Ï‚\n",
        "dataframe = pd.read_csv('climate_change.csv')\n",
        "print(dataframe.head(5))\n",
        "print(\"Î”Î¹Î±ÏƒÏ„Î¬ÏƒÎµÎ¹Ï‚:\", dataframe.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgvJhpZFIGlT",
        "outputId": "f7cc6902-597f-41cb-8db8-be144976724a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Year  Month    MEI     CO2      CH4      N2O   CFC-11   CFC-12        TSI  \\\n",
            "0  1983      5  2.556  345.96  1638.59  303.677  191.324  350.113  1366.1024   \n",
            "1  1983      6  2.167  345.52  1633.71  303.746  192.057  351.848  1366.1208   \n",
            "2  1983      7  1.741  344.15  1633.22  303.795  192.818  353.725  1366.2850   \n",
            "3  1983      8  1.130  342.25  1631.35  303.839  193.602  355.633  1366.4202   \n",
            "4  1983      9  0.428  340.17  1648.40  303.901  194.392  357.465  1366.2335   \n",
            "\n",
            "   Aerosols   Temp  \n",
            "0    0.0863  0.109  \n",
            "1    0.0794  0.118  \n",
            "2    0.0731  0.137  \n",
            "3    0.0673  0.176  \n",
            "4    0.0619  0.149  \n",
            "Î”Î¹Î±ÏƒÏ„Î¬ÏƒÎµÎ¹Ï‚: (308, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± custom Î±Î½Ï„Î¹ÎºÎµÎ¹Î¼Î­Î½Î¿Ï… Dataset\n",
        "\n",
        "Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¿ÏÎ¼Îµ Î­Î½Î± Î±Î½Ï„Î¹ÎºÎµÎ¯Î¼ÎµÎ½Î¿ Dataset Ï„Î¿ Î¿Ï€Î¿Î¯Î¿ Î¸Î± Ï„ÏÎ¿Ï†Î¿Î´Î¿Ï„Î®ÏƒÎµÎ¹ Ï„Î¿Ï…Ï‚ dataloaders, ÎºÎ±Î¹ Î­Î½Î± Î±Î½Ï„Î¹ÎºÎµÎ¯Î¼ÎµÎ½Î¿ transform Ï€Î¿Ï… Î¸Î± Ï„ÏÎ¿Ï€Î¿Ï€Î¿Î¹ÎµÎ¯ Ï„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± Ï€ÏÎ¹Î½ Î´Î¹Î±Î²Î±ÏƒÏ„Î¿ÏÎ½ Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ loaders.\n",
        "\n",
        "Î£Ï„Î¿ Î¼Î­Î»Î»Î¿Î½ Ï„Î¿ transform Î¸Î± ÎµÎ¯Î½Î±Î¹ Ï€Î¿Î»Ï ÏƒÎ·Î¼Î±Î½Ï„Î¹ÎºÏŒ Î³Î¹Î± Ï„Î¿ data augmentation, Î±Î»Î»Î¬ Î³Î¹Î± Ï„Î·Î½ ÏÏÎ± Ï„Î¿ Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î¿ÏÎ¼Îµ Î³Î¹Î± Ï„Î·Î½ ÎºÎ±Î½Î¿Î½Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· Ï„Ï‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½."
      ],
      "metadata": {
        "id": "Fd9abT0PwEbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ClimateDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, csv_file, transform=None, train=True):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      csv_file (string): Path to the csv file\n",
        "      transform (callable, optional): Optional transform to be applied\n",
        "          on each sample.\n",
        "      train (bool): whether to create the training set or the test set\n",
        "    \"\"\"\n",
        "\n",
        "    # ÎŸÏÎ¯Î¶Î¿Ï…Î¼Îµ Ï„Î¿ Î¼Î­Î³ÎµÎ¸Î¿Ï‚ Ï„Î¿Ï… training set\n",
        "    train_set_size = 250\n",
        "\n",
        "    # Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Ï„Î¿Ï… csv Î¼Î­ÏƒÏ‰ Pandas, Î´Î¹Î±Î³ÏÎ±Ï†Î® ÏƒÏ„Î·Î»ÏÎ½ Ï€Î¿Ï… Î´Îµ Î²Î¿Î·Î¸Î¿ÏÎ½ ÏƒÏ„Î·Î½ Î±Î½Î¬Î»Ï…ÏƒÎ·,\n",
        "    # Î¼ÎµÏ„Î±Ï„ÏÎ¿Ï€Î® Ï„Ï‰Î½ Pandas Dataframes ÏƒÎµ Numpy Arrays, Ï€Î¿Ï… Î­Ï‡Î¿Ï…Î½ Ï€Î¹Î¿ Î²Î¿Î·Î¸Î·Ï„Î¹ÎºÎ­Ï‚\n",
        "    # Î¹Î´Î¹ÏŒÏ„Î·Ï„ÎµÏ‚\n",
        "    dataframe = pd.read_csv(csv_file)\n",
        "    targets = np.array(dataframe[['Temp']]).astype('float32')\n",
        "    data = np.array(dataframe.drop(columns=['Year','Month','Temp'])).astype('float32')\n",
        "\n",
        "    # Î”Î¹Î±Ï‡Ï‰ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Ï„Ï‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ ÏƒÎµ training ÎºÎ±Î¹ test set\n",
        "    # Î‘Ï…Ï„Î® Î· Î³ÏÎ±Î¼Î¼Î® Î¸Î± Ï€ÏÎ­Ï€ÎµÎ¹ ÏƒÏ„Î¿ Î¼Î­Î»Î»Î¿Î½ Î½Î± Î±Î½Ï„Î¹ÎºÎ±Ï„Î±ÏƒÏ„Î±Î¸ÎµÎ¯ Î±Î½ Î¸Î­Î»Î¿Ï…Î¼Îµ Î½Î± ÎºÎ¬Î½Î¿Ï…Î¼Îµ \n",
        "    # Ï€Î¹Î¿ ÏÎµÎ±Î»Î¹ÏƒÏ„Î¹ÎºÎ® Î±Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ·\n",
        "    # Î˜Î­Ï„Î¿Ï…Î¼Îµ ÎºÎ±Î¹ Ï„Î¿ seed ÏƒÏ„Î¿ random state Î³Î¹Î± Î»ÏŒÎ³Î¿Ï…Ï‚ ÎµÏ€Î±Î½Î±Î»Î·ÏˆÎ¹Î¼ÏŒÏ„Î·Ï„Î±Ï‚\n",
        "    train_data, test_data, train_targets, test_targets = train_test_split(data, \n",
        "                            targets, train_size=train_set_size, random_state=665)\n",
        "\n",
        "    # Î˜Î­Ï„Î¿Ï…Î¼Îµ ÎºÎ±Î¹ Î±ÏÏ‡Î¹ÎºÎ¿Ï€Î¿Î¹Î¿ÏÎ¼Îµ Ï„Î¿ transform\n",
        "    self.transform = transform\n",
        "    # Î ÏÎ¿ÏƒÎ¿Ï‡Î®, Ï„Î¿ transform Î±ÏÏ‡Î¹ÎºÎ¿Ï€Î¿Î¹ÎµÎ¯Ï„Î±Î¹ Î¼Îµ Ï„Î¹Ï‚ Ï„Î¹Î¼Î­Ï‚ Ï„Î¿Ï… training set, ÎµÎ¯Ï„Îµ\n",
        "    # Ï„Î¿ Dataset Î±Ï†Î¿ÏÎ¬ Ï„Î¿ train ÎµÎ¯Ï„Îµ Ï„Î¿ test set.\n",
        "    self.transform.fit(train_data, train_targets)\n",
        "\n",
        "    # Î‘Î½ Î¼Î±Ï‚ Î­Ï‡ÎµÎ¹ Î¶Î·Ï„Î·Î¸ÎµÎ¯ Î½Î± Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î·Î¸ÎµÎ¯ train database, ÎºÏÎ±Ï„Î¬Î¼Îµ Ï„Î± train data.\n",
        "    # Î‘Î»Î»Î¹ÏÏ‚ ÎºÏÎ±Ï„Î¬Î¼Îµ Ï„Î± test data. \n",
        "    if train==True:\n",
        "      self.data = train_data\n",
        "      self.targets = train_targets\n",
        "    else:\n",
        "      self.data = test_data\n",
        "      self.targets = test_targets\n",
        "    # Î— Î±ÏÏ‡Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· Ï„ÎµÎ»ÎµÎ¹ÏÎ½ÎµÎ¹ ÎµÎ´Ï\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # Î‰ __len__ ÎµÎ½ÏŒÏ‚ Î±Î½Ï„Î¹ÎºÎµÎ¹Î¼Î­Î½Î¿Ï… Dataset Î¿Ï†ÎµÎ¯Î»ÎµÎ¹ Î½Î± ÎµÏ€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ Ï„Î¿ Ï€Î»Î®Î¸Î¿Ï‚ Ï„Ï‰Î½\n",
        "  # Î±Î½Ï„Î¹ÎºÎµÎ¹Î¼Î­Î½Ï‰Î½ Ï„Î¿Ï….\n",
        "  def __len__(self):\n",
        "    return len(self.targets)\n",
        "\n",
        "  # Î— __getitem__ ÎµÎ½ÏŒÏ‚ Î±Î½Ï„Î¹ÎºÎµÎ¹Î¼Î­Î½Î¿Ï… Dataset Ï€Î±Î¯ÏÎ½ÎµÎ¹ Ï‰Ï‚ Ï€Î±ÏÎ¬Î¼ÎµÏ„ÏÎ¿ Î­Î½Î± index ÎºÎ±Î¹ \n",
        "  # ÎµÏ€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ Ï„Î¿ Î±Î½Ï„Î¯ÏƒÏ„Î¿Î¹Ï‡Î¿ Î±Î½Ï„Î¹ÎºÎµÎ¯Î¼ÎµÎ½Î¿. Î¤Î· Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÎµÎ¯ Î¿ DataLoader Î³Î¹Î± Î½Î± \n",
        "  # Î±Î½Ï„Î»ÎµÎ¯ minibatches.\n",
        "  def __getitem__(self, idx):\n",
        "    if torch.is_tensor(idx):\n",
        "      idx = idx.tolist()\n",
        "    item_data = self.data[idx,:]\n",
        "    item_target = self.targets[idx,:]\n",
        "    \n",
        "    # Î‘Î½ Î­Ï‡Î¿Ï…Î¼Îµ Î¿ÏÎ¯ÏƒÎµÎ¹ transform, Ï„Î¿ ÎµÏ†Î±ÏÎ¼ÏŒÎ¶Î¿Ï…Î¼Îµ ÏƒÏ„Î¿ Î±Î½Ï„Î¹ÎºÎµÎ¯Î¼ÎµÎ½Î¿ Ï€ÏÎ¹Î½ Ï„Î¿ \n",
        "    # ÎµÏ€Î¹ÏƒÏ„ÏÎ­ÏˆÎ¿Ï…Î¼Îµ. ÎŒÏ„Î±Î½ ÎºÎ±Î»Ï Ï„Î¿ transform Î¼Îµ Ï„Î¿ ÏŒÎ½Î¿Î¼Î¬ Ï„Î¿Ï…, ÏƒÏ„Î·Î½ Ï€ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÏŒÏ„Î·Ï„Î±\n",
        "    # ÎºÎ±Î»ÎµÎ¯Ï„Î±Î¹ Î· transform.__call__() (Î²Î». Ï€Î±ÏÎ±ÎºÎ¬Ï„Ï‰)\n",
        "    if self.transform:\n",
        "      item_data, item_target = self.transform(item_data, item_target)\n",
        "    return item_data, item_target\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Î— ÎºÎ»Î¬ÏƒÎ· Î±Ï…Ï„Î® Î¸Î± Ï€Î±Î¯Î¾ÎµÎ¹ Ï„Î¿ ÏÏŒÎ»Î¿ Ï„Î¿Ï… Transform. Î˜Î± Î±Ï†Î±Î¹ÏÎµÎ¯ Ï„Î·Î½ ÎµÎ»Î¬Ï‡Î¹ÏƒÏ„Î· Ï„Î¹Î¼Î®\n",
        "# Î±Ï€ÏŒ ÎºÎ¬Î¸Îµ ÏƒÏ„Î®Î»Î· Ï„Ï‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ ÎºÎ±Î¹ Î¸Î± Î´Î¹Î±Î¹ÏÎµÎ¯ Î¼Îµ Ï„Î¿ Ï†Î¬ÏƒÎ¼Î± Ï„Î·Ï‚, ÏÏƒÏ„Îµ Î½Î± ÎºÎ±Î½Î¿Î½Î¹ÎºÎ¿Ï€Î¿Î¹ÎµÎ¯\n",
        "# Ï„Î¹Ï‚ Ï„Î¹Î¼Î­Ï‚ ÏŒÎ»Ï‰Î½ Ï„Ï‰Î½ Î¼ÎµÏ„Î±Î²Î»Î·Ï„ÏÎ½ (ÎºÎ±Î¹ Ï„Ï‰Î½ ÏƒÏ„ÏŒÏ‡Ï‰Î½) ÏƒÏ„Î¿ [0,1]\n",
        "class MinMaxScaler():\n",
        "\n",
        "  # H fit Î±ÏÏ‡Î¹ÎºÎ¿Ï€Î¿Î¹ÎµÎ¯Ï„Î±Î¹ Î¼Îµ Ï„Î± training data, ÎºÎ±Î¹ Ï…Ï€Î¿Î»Î¿Î³Î¯Î¶ÎµÎ¹ Ï„Î¹Ï‚ ÎµÎ»Î¬Ï‡Î¹ÏƒÏ„ÎµÏ‚ ÎºÎ±Î¹ \n",
        "  # Î¼Î­Î³Î¹ÏƒÏ„ÎµÏ‚ Ï„Î¹Î¼Î­Ï‚. Î¤Î± Î±Î½Ï„Î¹ÎºÎµÎ¯Î¼ÎµÎ½Î± ÎµÎ¯Î½Î±Î¹ numpy arrays, Î¿Ï€ÏŒÏ„Îµ Î­Ï‡Î¿Ï…Î½ ÎµÎ½ÏƒÏ‰Î¼Î±Ï„Ï‰Î¼Î­Î½Î·\n",
        "  # Ï„Î· ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ· min ÎºÎ±Î¹ max \n",
        "  def fit(self, data, targets):\n",
        "    self.data_min = data.min(0, keepdims=True)\n",
        "    self.target_min = targets.min(0, keepdims=True)\n",
        "    self.data_max = data.max(0, keepdims=True)\n",
        "    self.target_max = targets.max(0, keepdims=True)\n",
        "    return self\n",
        "\n",
        "  # ÎŒÏ„Î±Î½ ÎºÎ±Î»ÎµÎ¯Ï„Î±Î¹ Î· transform.__call__(), Î´Î­Ï‡ÎµÏ„Î±Î¹ Î­Î½Î± Î±Î½Ï„Î¹ÎºÎµÎ¯Î¼ÎµÎ½Î¿ (data ÎºÎ±Î¹ target)\n",
        "  # ÎºÎ±Î¹ Ï„Î¿ ÎµÏ€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ Î¼ÎµÏ„Î±ÏƒÏ‡Î·Î¼Î±Ï„Î¹ÏƒÎ¼Î­Î½Î¿ -ÎµÎ½ Ï€ÏÎ¿ÎºÎµÎ¹Î¼Î­Î½Ï‰ ÎºÎ±Î½Î¿Î½Î¹ÎºÎ¿Ï€Î¿Î¹Î·Î¼Î­Î½Î¿\n",
        "  def __call__(self, data, target):\n",
        "    data = (data - self.data_min)/(self.data_max-self.data_min)\n",
        "    target = (target - self.target_min)/(self.target_max-self.target_min)\n",
        "    return data, target\n",
        "\n",
        "  # Î˜Î± ÎµÎºÏ€Î±Î¹Î´ÎµÏÏƒÎ¿Ï…Î¼Îµ Î­Î½Î± ÏƒÏÏƒÏ„Î·Î¼Î± Î½Î± Î¼Î±Î¸Î±Î¯Î½ÎµÎ¹ Ï„Î± ÎºÎ±Î½Î¿Î½Î¹ÎºÎ¿Ï€Î¿Î¹Î·Î¼Î­Î½Î± targets. Î“Î¹Î±\n",
        "  # ÎµÏ†Î±ÏÎ¼Î¿Î³Î® ÏƒÏ„Î¿Î½ Ï€ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÏŒ ÎºÏŒÏƒÎ¼Î¿, Î¸Î± Ï‡ÏÎµÎ¹Î±ÏƒÏ„ÎµÎ¯ Î½Î± Î¼Ï€Î¿ÏÎ¿ÏÎ¼Îµ Î½Î± Î¼ÎµÏ„Î±ÏƒÏ‡Î·Î¼Î±Ï„Î¯Î¶Î¿Ï…Î¼Îµ\n",
        "  # Ï„Î± outputs Ï„Î¿Ï… ÏƒÏ…ÏƒÏ„Î®Î¼Î±Ï„Î¿Ï‚ Ï€Î¯ÏƒÏ‰ ÏƒÏ„Î¿ Î±ÏÏ‡Î¹ÎºÏŒ Ï†Î¬ÏƒÎ¼Î± Ï„Î¹Î¼ÏÎ½ Ï„Î¿Ï…\n",
        "  def inverse_transform(self, data, target):\n",
        "    data=data * (self.data_max-self.data_min) + self.data_min\n",
        "    target = target * (self.target_max-self.target_min) + self.target_min\n",
        "    return data, target"
      ],
      "metadata": {
        "id": "1y_r_4ngKxAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± DataLoaders\n",
        "\n",
        "Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¿ÏÎ¼Îµ dataloaders Î³Î¹Î± Ï„Î¿ training set ÎºÎ±Î¹ Î³Î¹Î± Ï„Î¿ test set."
      ],
      "metadata": {
        "id": "SUa7z3yH0t5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To batch size ÎµÎ¯Î½Î±Î¹ Î±ÏÎºÎµÏ„Î¬ Î¼ÎµÎ³Î¬Î»Î¿ ÏÏƒÏ„Îµ Î½Î± Ï‡Ï‰ÏÎ¬ÎµÎ¹ ÏŒÎ»Î± Ï„Î± training data ÎºÎ±Î¹ ÏŒÎ»Î± \n",
        "# Ï„Î± test data ÏƒÎµ Î­Î½Î± loop (Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ¬ ÎµÏ†Î±ÏÎ¼ÏŒÎ¶Î¿Ï…Î¼Îµ Batch Gradient Descent, ÎºÎ¬Î¸Îµ\n",
        "# Batch ÎµÎ¯Î½Î±Î¹ Î­Î½Î± Epoch) \n",
        "# (Î±Î½ Ï„Î¿ batch size ÎµÎ¯Î½Î±Î¹ Î¼ÎµÎ³Î±Î»ÏÏ„ÎµÏÎ¿ Î±Ï€ÏŒ Ï„Î± Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î±, Î· pytorch \n",
        "# Î´Î·Î¼Î¹Î¿Ï…ÏÎ³ÎµÎ¯ Î­Î½Î± batch Î¼Îµ Ï„Î± Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î±)\n",
        "batch_size = 500\n",
        "transform=MinMaxScaler()\n",
        "\n",
        "train_dataset = ClimateDataset(csv_file='climate_change.csv', train=True, transform=transform)\n",
        "test_dataset = ClimateDataset(csv_file='climate_change.csv', train=False, transform=transform)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "YQmvU0I50tBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Î‘ÏÏ‡Î¹Ï„ÎµÎºÏ„Î¿Î½Î¹ÎºÎ® Î´Î¹ÎºÏ„ÏÎ¿Ï…\n",
        "\n",
        "ÎŸÏÎ¯Î¶Î¿Ï…Î¼Îµ Î­Î½Î± Î±Ï€Î»ÏŒ Î´Î¯ÎºÏ„Ï…Î¿ Î¼Îµ Î­Î½Î±Î½ Î½ÎµÏ…ÏÏÎ½Î± Î³Î¹Î± Î³ÏÎ±Î¼Î¼Î¹ÎºÎ® Ï€Î±Î»Î¹Î½Î´ÏÏŒÎ¼Î·ÏƒÎ·"
      ],
      "metadata": {
        "id": "doGIwzMX1FP3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ÎšÏÎ´Î¹ÎºÎ±Ï‚ Î¿ÏÎ¹ÏƒÎ¼Î¿Ï Ï„Î¿Ï… Î´Î¹ÎºÏ„ÏÎ¿Ï…\n",
        "class NeuralNetwork1(nn.Module):\n",
        "  def __init__(self):\n",
        "    # Î¤ÏÎ­Ï‡Ï‰ Ï„Î·Î½ init Ï„Î·Ï‚ ÎºÎ»Î¬ÏƒÎ·Ï‚-Î³Î¿Î½Î¹Î¿Ï\n",
        "    super(NeuralNetwork1, self).__init__()\n",
        "    \n",
        "    #Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Ï Î¼Î¹Î± Î±ÏÏ‡Î¹Ï„ÎµÎºÏ„Î¿Î½Î¹ÎºÎ® Ï€Î¿Ï… Î¸Î± Î±Ï€Î¿Ï„ÎµÎ»ÎµÎ¯Ï„Î±Î¹ Î±Ï€Î¿ÎºÎ»ÎµÎ¹ÏƒÏ„Î¹ÎºÎ¬ Î±Ï€ÏŒ Î­Î½Î±Î½ Î½ÎµÏ…ÏÏÎ½Î± Î¼Îµ Î³ÏÎ±Î¼Î¼Î¹ÎºÎ® ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ· ÎµÎ½ÎµÏÎ³Î¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚.\n",
        "    self.network_architecture = nn.Sequential(\n",
        "        nn.Linear(8, 1),\n",
        "        #Î¤Î¿ input ğ± Ï„Î¿Ï… Î´Î¹ÎºÏ„ÏÎ¿Ï… Î±Ï€Î¿Ï„ÎµÎ»ÎµÎ¹Ï„Î±Î¹ Î±Ï€Î¿ 8 Î¼ÎµÏ„Î±Î²Î»Î·Ï„ÎµÏ‚, ÎºÎ±Î¸Ï‰Ï‚ ÎºÎ±Ï„Î± Ï„Î·Î½ Ï€ÏÎ¿ÎµÏÎ³Î±ÏƒÎ¯Î± Î±Ï€ÏŒ Ï„Î·Î½ ÎºÎ»Î¬ÏƒÎ· ClimateDataset Î±Ï†Î±Î¹ÏÎµÏƒÎ±Î¼Îµ Ï„Î± targets, 'Temp', ÎºÎ±Î¹ Ï„Î¹Ï‚ ÏƒÏ„Î·Î»ÎµÏ‚ 'Year' ÎºÎ±Î¹ 'Month'.\n",
        "        )\n",
        "    \n",
        "  def forward(self, x):\n",
        "    logits = self.network_architecture(x)\n",
        "    return logits"
      ],
      "metadata": {
        "id": "SWZzmPr01XuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training ÎºÎ±Î¹ Test Loop\n",
        "\n",
        "Î“ÏÎ¬Ï†Î¿Ï…Î¼Îµ Ï„Î¿Î½ ÎºÏÎ´Î¹ÎºÎ± Ï„Î¿Ï… training loop ÎºÎ±Î¹ Ï„Î¿Ï… test loop"
      ],
      "metadata": {
        "id": "CSZJ-_-K1YRI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer, display):\n",
        "    size = len(dataloader.dataset)\n",
        "    \n",
        "    \n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "      # ÎšÎ¬Î¸Îµ batch Î­Ï‡ÎµÎ¹ Î´Î¹Î±ÏƒÏ„Î¬ÏƒÎµÎ¹Ï‚ [250, 1, 8]\n",
        "      # Compute prediction and loss\n",
        "      pred = model(X)\n",
        "      loss = loss_fn(pred, y)\n",
        "\n",
        "      # Backpropagation\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      if display % 100 == 0:\n",
        "        loss, current = loss.item(), len(X)\n",
        "        print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "    TheTargets = []\n",
        "    ThePredictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "  \n",
        "    for i in y:\n",
        "      TheTargets.append(i.item())\n",
        "    \n",
        "    for j in pred:\n",
        "      ThePredictions.append(j.item())\n",
        "\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "  \n",
        "    print(f\"Test Error: \\n R2 Score: {r2_score(TheTargets, ThePredictions)} , Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "ffBgVWDpbVef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Î£Ï…Î½Î¬ÏÏ„Î·ÏƒÎ· ÎºÏŒÏƒÏ„Î¿Ï…Ï‚ (Loss Function)"
      ],
      "metadata": {
        "id": "AWkrWGr5lZTE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ÎŸÏÎ¯Î¶Î¿Ï…Î¼Îµ Ï‰Ï‚ Loss Function Ï„Î·Î½ MSELoss() (ÎœÎ­ÏƒÎ¿ Î¤ÎµÏ„ÏÎ±Î³Ï‰Î½Î¹ÎºÏŒ Î£Ï†Î¬Î»Î¼Î±) ÎºÎ±Î¸ÏÏ‚ ÎµÎ¹Î½Î±Î¹ ÎºÎ±Ï„Î¬Î»Î»Î·Î»Î· Î³Î¹Î± Ï€ÏÎ¿Î²Î»Î·Î¼Î±Ï„Î± Ï€Î±Î»Î¹Î½Î´ÏÏŒÎ¼Î·ÏƒÎ·Ï‚.\n",
        "loss_fn = nn.MSELoss()"
      ],
      "metadata": {
        "id": "2gIf_sxrlszS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ÎŸÏÎ¹ÏƒÎ¼ÏŒÏ‚ Ï…Ï€ÎµÏÏ€Î±ÏÎ±Î¼Î­Ï„ÏÏ‰Î½ ÎºÎ±Î¹ ÎµÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ· Î´Î¹ÎºÏ„ÏÎ¿Ï…\n",
        "\n",
        "ÎšÏÎ´Î¹ÎºÎ±Ï‚ ÎµÎºÏ„Î­Î»ÎµÏƒÎ·Ï‚ ÎºÎ±Î¹ Î±Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ·Ï‚ Ï„Î¿Ï… Î´Î¹ÎºÏ„ÏÎ¿Ï… "
      ],
      "metadata": {
        "id": "RF_TfBa89VF4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Î¤Î¿ manual_seed ÎºÎ±Î¸Î¿ÏÎ¯Î¶ÎµÎ¹ Ï„Î·Î½ Ï„Ï…Ï‡Î±Î¯Î± Î±ÏÏ‡Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· Ï„Ï‰Î½ Î²Î±ÏÏÎ½/Ï€Î±ÏÎ±Î¼Î­Ï„ÏÏ‰Î½ Ï„Î¿Ï… Î´Î¹ÎºÏ„ÏÎ¿Ï…\n",
        "# Î ÏÏŒÎºÎµÎ¹Ï„Î±Î¹ Î±Ï€Î»ÏÏ‚ Î³Î¹Î± Î­Î½Î± ÏƒÏ„Î±Î¸ÎµÏÏŒ seed ÏƒÏ„Î¿ random number generator Ï„Î·Ï‚ pytorch.\n",
        "torch.manual_seed(100)\n",
        "#torch.manual_seed(50)\n",
        "\n",
        "model = NeuralNetwork1()\n",
        "learning_rate = 0.001\n",
        "epochs = 3000\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# ÎšÏÎ´Î¹ÎºÎ±Ï‚ ÎµÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·Ï‚ ÎµÎ´Ï:\n",
        "for t in range(epochs):\n",
        "    if t % 100 == 0:\n",
        "      print(f\"Epoch {t}\\n-------------------------------\")\n",
        "    train_loop(train_dataloader, model, loss_fn, optimizer, t)\n",
        "    if t % 100 == 0:\n",
        "      test_loop(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "id": "f1beitvisMNY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78a506fb-fd9f-4fc7-ab6d-8bb7886a61a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n",
            "-------------------------------\n",
            "loss: 0.532136  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -25.27130098504746 , Avg loss: 0.551750 \n",
            "\n",
            "Epoch 100\n",
            "-------------------------------\n",
            "loss: 0.162329  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -6.7977772675125765 , Avg loss: 0.163769 \n",
            "\n",
            "Epoch 200\n",
            "-------------------------------\n",
            "loss: 0.068843  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -2.2233631332819366 , Avg loss: 0.067697 \n",
            "\n",
            "Epoch 300\n",
            "-------------------------------\n",
            "loss: 0.044570  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -1.0770251520030025 , Avg loss: 0.043622 \n",
            "\n",
            "Epoch 400\n",
            "-------------------------------\n",
            "loss: 0.037668  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -0.7669670089043794 , Avg loss: 0.037110 \n",
            "\n",
            "Epoch 500\n",
            "-------------------------------\n",
            "loss: 0.035157  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -0.6576277124832313 , Avg loss: 0.034813 \n",
            "\n",
            "Epoch 600\n",
            "-------------------------------\n",
            "loss: 0.033786  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -0.5958033873339577 , Avg loss: 0.033515 \n",
            "\n",
            "Epoch 700\n",
            "-------------------------------\n",
            "loss: 0.032740  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -0.5457179761920823 , Avg loss: 0.032463 \n",
            "\n",
            "Epoch 800\n",
            "-------------------------------\n",
            "loss: 0.031811  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -0.49949994500604467 , Avg loss: 0.031492 \n",
            "\n",
            "Epoch 900\n",
            "-------------------------------\n",
            "loss: 0.030945  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -0.45559646126668496 , Avg loss: 0.030570 \n",
            "\n",
            "Epoch 1000\n",
            "-------------------------------\n",
            "loss: 0.030128  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -0.4137473678410333 , Avg loss: 0.029692 \n",
            "\n",
            "Epoch 1100\n",
            "-------------------------------\n",
            "loss: 0.029354  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -0.3738906618494142 , Avg loss: 0.028854 \n",
            "\n",
            "Epoch 1200\n",
            "-------------------------------\n",
            "loss: 0.028619  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -0.3359642905459408 , Avg loss: 0.028058 \n",
            "\n",
            "Epoch 1300\n",
            "-------------------------------\n",
            "loss: 0.027922  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -0.2998867399881162 , Avg loss: 0.027300 \n",
            "\n",
            "Epoch 1400\n",
            "-------------------------------\n",
            "loss: 0.027259  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -0.2655664372968287 , Avg loss: 0.026579 \n",
            "\n",
            "Epoch 1500\n",
            "-------------------------------\n",
            "loss: 0.026630  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -0.2329104557381554 , Avg loss: 0.025894 \n",
            "\n",
            "Epoch 1600\n",
            "-------------------------------\n",
            "loss: 0.026031  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -0.20182900151120875 , Avg loss: 0.025241 \n",
            "\n",
            "Epoch 1700\n",
            "-------------------------------\n",
            "loss: 0.025462  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -0.1722343737268781 , Avg loss: 0.024619 \n",
            "\n",
            "Epoch 1800\n",
            "-------------------------------\n",
            "loss: 0.024921  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -0.1440447210020226 , Avg loss: 0.024027 \n",
            "\n",
            "Epoch 1900\n",
            "-------------------------------\n",
            "loss: 0.024406  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -0.11718236977530316 , Avg loss: 0.023463 \n",
            "\n",
            "Epoch 2000\n",
            "-------------------------------\n",
            "loss: 0.023916  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -0.09157474144168254 , Avg loss: 0.022925 \n",
            "\n",
            "Epoch 2100\n",
            "-------------------------------\n",
            "loss: 0.023449  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -0.06715276105289125 , Avg loss: 0.022412 \n",
            "\n",
            "Epoch 2200\n",
            "-------------------------------\n",
            "loss: 0.023004  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -0.043852030264690534 , Avg loss: 0.021923 \n",
            "\n",
            "Epoch 2300\n",
            "-------------------------------\n",
            "loss: 0.022580  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -0.0216114736130939 , Avg loss: 0.021456 \n",
            "\n",
            "Epoch 2400\n",
            "-------------------------------\n",
            "loss: 0.022176  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -0.00037365743105377547 , Avg loss: 0.021010 \n",
            "\n",
            "Epoch 2500\n",
            "-------------------------------\n",
            "loss: 0.021791  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.019915893676952234 , Avg loss: 0.020584 \n",
            "\n",
            "Epoch 2600\n",
            "-------------------------------\n",
            "loss: 0.021423  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.03930812753334534 , Avg loss: 0.020176 \n",
            "\n",
            "Epoch 2700\n",
            "-------------------------------\n",
            "loss: 0.021071  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.05785126016297204 , Avg loss: 0.019787 \n",
            "\n",
            "Epoch 2800\n",
            "-------------------------------\n",
            "loss: 0.020736  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.07559023779081187 , Avg loss: 0.019414 \n",
            "\n",
            "Epoch 2900\n",
            "-------------------------------\n",
            "loss: 0.020415  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.09256793853624656 , Avg loss: 0.019058 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Î¤Î¹ Ï€Î±ÏÎ±Ï„Î·ÏÎµÎ¯Ï„Îµ Î½Î± ÏƒÏ…Î¼Î²Î±Î¯Î½ÎµÎ¹ ÏƒÏ„Î± train/test loss ÎºÎ±Î¹ ÏƒÏ„Î¿ R2 score ÎºÎ±Î¸ÏÏ‚ Ï€ÎµÏÎ½Î¬Î½Îµ Ï„Î± Epochs;\n",
        "\n",
        "Î‘Ï€Î¬Î½Ï„Î·ÏƒÎ·: ÎšÎ±Î¸ÏÏ‚ Ï€ÎµÏÎ½Î¬Î½Îµ Ï„Î± Epochs Î¼Ï€Î¿ÏÎ¿Ï…Î¼Îµ Î½Î± Ï€Î±ÏÎ±Ï„Î·ÏÎ®ÏƒÎ¿Ï…Î¼Îµ ÏŒÏ„Î¹ ÏŒÏƒÎ¿Î½ Î±Ï†Î¿ÏÎ¬ Ï„Î¿ train Loss Î±Ï…Ï„ÏŒ Î¼ÎµÎ¹ÏÎ½ÎµÏ„Î±Î¹ ÏƒÏ…Î½ÎµÏ‡Ï‰Ï‚, Î¾ÎµÎºÎ¹Î½ÏÎ½Ï„Î±Ï‚ Î±Ï€Î¿ Ï„Î¿ 1Î¿ epoch Î²Î»ÎµÏ€Î¿Ï…Î¼Îµ Î¿Ï„Î¹ Ï„Î¿ Loss ÎµÎ¹Î½Î±Î¹ 0.532136 ÎºÎ±Î¹ ÏƒÏ„Î·Î½ ÏƒÏ…Î½ÎµÏ‡ÎµÎ¹Î± Ï€Î±ÏÎ¿Ï…ÏƒÎ¹Î¬Î¶ÎµÎ¹ Î¼ÎµÎ³Î¬Î»Î· Î¼ÎµÎ¯Ï‰ÏƒÎ· Î¼Î­Ï‡ÏÎ¹ Î½Î± Ï†Ï„Î±ÏƒÎµÎ¹ ÏƒÏ„Î¿ 0.029354 ÎºÎ±Î¹ Î½Î± ÎºÎ±Ï„Î±Î»Î·Î¾ÎµÎ¹ ÏƒÏ„Î¿ 0.020415.\n",
        "\n",
        "ÎŒÏƒÎ¿Î½ Î±Ï†Î¿ÏÎ± Ï„Î¿ test Loss Î¼Ï€Î¿ÏÎ¿ÏÎ¼Îµ Î½Î± Ï€Î±ÏÎ±Ï„Î®ÏÎ·ÏƒÎ¿Ï…Î¼Îµ ÏŒÏ„Î¹ ÎºÎ±Î¹ Î±Ï…Ï„Î¿ Î¼ÎµÎ¹ÏÎ½ÎµÏ„Î±Î¹ ÏƒÏ„Î±Î´Î¹Î±ÎºÎ¬ Ï€Î±ÏÎ¿Ï…ÏƒÎ¹Î¬Î¶Î¿Î½Ï„Î±Ï‚ Î¼ÎµÎ³Î¬Î»Î· Î¼ÎµÎ¹Ï‰ÏƒÎ· ÏƒÏ„Î± Ï€ÏÏÏ„Î± 400 epochs Ï‰ÏƒÏ€Î¿Ï… Î½Î± ÎºÎ±Ï„Î±Î»Î®Î¾ÎµÎ¹ ÏƒÏ„Î¿ 0.019058.\n",
        "\n",
        "Î¤Î¿ R2 score Ï€Î±ÏÎ±Ï„Î·ÏÎ¿ÏÎ¼Îµ ÏŒÏ„Î¹ ÎºÎ±Î¹ Î±Ï…Ï„Î¿ Î±Ï…Î¾Î¬Î½ÎµÏ„Î±Î¹. ÎˆÏ‡Î¿Î½Ï„Î±Ï‚ Î±ÏÏ‡Î¹ÎºÎ¬ Î±ÏÎ½Î·Ï„Î¹ÎºÎ­Ï‚ Ï„Î¹Î¼Î­Ï‚ (<0) Ï€ÏÎ¬Î³Î¼Î± Ï€Î¿Ï… ÏƒÎ·Î¼Î±Î¯Î½ÎµÎ¹ ÏŒÏ„Î¹ Ï„Î¿ Î¼Î¿Î½Ï„ÎµÎ»Î¿ Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹ Î±ÏÎºÎµÏ„Î± ÎºÎ±Î»ÏŒ.\n",
        "ÎœÎµÏ„Î¬ Î±Ï€Î¿ 2500 epochs Ï€Î±ÏÎ±Ï„Î·ÏÎ¿ÏÎ¼Îµ ÏŒÏ„Î¹ Î· Ï„Î¹Î¼Î® Ï„Î¿Ï… R2 Score ÎµÎ¹Î½Î±Î¹ Ï€Î»Î­Î¿Î½ Î¼ÎµÎ³Î±Î»ÏÏ„ÎµÏÎ· Ï„Î¿Ï… 0. Î¤ÎµÎ»Î¿Ï‚, Î­Ï‡Î¿Î½Ï„Î±Ï‚ R2 Score: **0.09256793853624656**, ÏƒÏ…Î¼Ï€ÎµÏÎ±Î¯Î½Î¿Ï…Î¼Îµ ÏŒÏ„Î¹ Ï„Î¿ Ï€Î¿ÏƒÎ¿ÏƒÏ„ÏŒ Ï„Î·Ï‚ Î´Î¹Î±ÏƒÏ€Î¿ÏÎ¬Ï‚ Ï„Ï‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ Ï€Î¿Ï… ÎµÎºÏ†ÏÎ¬Î¶ÎµÏ„Î±Î¹ ÏƒÏ‰ÏƒÏ„Î¬ Î±Ï€ÏŒ Ï„Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ ÎµÎ¹Î½Î±Î¹ Î±ÏÎºÎµÏ„Î± Î¼Î¹ÎºÏÏŒ ÎºÎ±Î¸Ï‰Ï‚ Ï†Ï„Î±Î½ÎµÎ¹ Î¼Î¿Î»Î¹Ï‚ ÏƒÏ„Î¿ 0.09  "
      ],
      "metadata": {
        "id": "Dv_ER0oIsgqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Î¤Î¹ Ï€Î±ÏÎ±Ï„Î·ÏÎµÎ¯Ï„Îµ ÏƒÎµ ÏƒÏ‡Î­ÏƒÎ· Î¼Îµ Ï„Î¹Ï‚ Ï„Î¹Î¼Î­Ï‚ Ï„Ï‰Î½ Î¼ÎµÏ„ÏÎ¹ÎºÏÎ½ ÏƒÏ„Î¿ Ï‡ÏÏŒÎ½Î¿; Î¤Î¹ Î¼Ï€Î¿ÏÎµÎ¯Ï„Îµ Î½Î± ÏƒÏ…Î¼Ï€ÎµÏÎ¬Î½ÎµÏ„Îµ Î±Ï€ÏŒ Î±Ï…Ï„ÏŒ;\n",
        "\n",
        "Î‘Ï€Î¬Î½Ï„Î·ÏƒÎ·:\n",
        "> Î“Î¹Î± torch.manual_seed(100): Î™ÏƒÏ‡ÏÎµÎ¹ ÏŒÏ„Î¹ Ï€ÏÎ¿Î±Î½Î­Ï†ÎµÏÎ± Ï€Î±ÏÎ±Ï€Î¬Î½Ï‰ Î³Î¹Î± Ï„Î± train/test loss ÎºÎ±Î¹ R2 Score. Î£Ï…Î¼Ï€Î±Î¹ÏÎ­Î½Î¿Ï…Î¼Îµ ÏŒÏ„Î¹ Î¿Î¹ Ï„Î¹Î¼Î­Ï‚ Ï„Ï‰Î½ Î¼ÎµÏ„ÏÎ¹ÎºÏÎ½ Î¼ÎµÎ¹ÏÎ½Î¿Î½Ï„Î±Î¹ ÏƒÏ„Î·Î½ Î´ÎµÎ¹Î¬ÏÎºÎµÎ¹Î± Ï„Î¿Ï… Ï‡ÏÏŒÎ½Î¿Ï… Î¼Îµ Î¹Î´Î¹Î±Î¯Ï„ÎµÏÎ· Î¼ÎµÏ„Î±Î²Î¿Î»Î® ÏƒÏ„Î·Î½ Î±ÏÏ‡Î· ÎºÎ±Î¸Ï‰Ï‚ Ï„Î± weights Î±Ï€Î¿ random Ï€Î¿Ï… ÎµÎ¹Î½Î±Î¹ Î±ÏÏ‡Î¹ÎºÎ± Î¼ÎµÏ„Î± Î±ÏÏ‡Î¯Î¶Î¿Ï…Î½ ÏƒÏ„Î±Î´Î¹Î±ÎºÎ± Î½Î± Î²ÎµÎ»Ï„Î¹ÏÎ½Î¿Î½Ï„Î±Î¹.\n",
        "\n",
        "\n",
        "\n",
        "> Î“Î¹Î± torch.manual_seed(50): Î Î±ÏÎ±Ï„Î·ÏÎ¿ÏÎ¼Îµ ÏŒÏ„Î¹ Î¿Î¹ Ï„Î¹Î¼Î­Ï‚ Ï„Ï‰Î½ Î¼ÎµÏ„ÏÎ¹ÎºÏÎ½ train, test Loss ÎºÎ±Î¹ R2 Score ÏƒÏ…Î½ÎµÏ‡ÏÏ‚ Î¼ÎµÎ¹ÏÎ½Î¿Î½Ï„Î±Î¹.Î•Ï€Î¹Ï€Î»Î­Î¿Î½, Î· Î²ÎµÎ»Ï„Î¯Ï‰ÏƒÎ· Ï„Ï‰Î½ Ï„Î¹Î¼ÏÎ½ ÏƒÎµ ÏƒÏ‡ÎµÏƒÎ· Î¼Îµ Ï€ÏÎ¹Î½ ÎµÎ¹Î½Î±Î¹ Î¼ÎµÎ³Î±Î»ÏÏ„ÎµÏÎ·. Î•Î¹Î´Î¹ÎºÏŒÏ„ÎµÏÎ± Ï„Î¿ R2 Score Î²Î»ÎµÏ€Î¿Ï…Î¼Îµ Î¿Ï„Î¹ ÎµÏ‡ÎµÎ¹ Î¼ÎµÎ³Î±Î»Ï…Ï„ÎµÏÎ· Î²ÎµÎ»Ï„Î¹Ï‰ÏƒÎ· ÏƒÏ„Î·Î½ Ï„Î¹Î¼Î® Ï„Î¿Ï… ÏƒÎµ ÏƒÏ‡ÎµÏƒÎ· Î¼Îµ Ï€ÏÎ¹Î½ ÎºÎ±Î¹ Î±Ï…Î¾Î·ÏƒÎ· Ï„Î·Ï‚ Ï„Î¹Î¼Î·Ï‚ ÎµÏ‰Ï‚ ÎºÎ±Î¹ **0.31448371739472414** Ï€Î¿Ï… ÎµÎ¹Î½Î±Î¹ ÏƒÏ…Î³ÎºÏÎ¹Ï„Î¹ÎºÎ± ÎºÎ±Î»Ï…Ï„ÎµÏÎ· Î¼Îµ Ï€ÏÎ¹Î½. Î Î±ÏÎ¿Î»Î±Ï…Ï„Î±, Î¼Ï€Î¿ÏÎ¿Ï…Î¼Îµ Î½Î± Ï€Î±ÏÎ±Ï„Î·ÏÎ·ÏƒÎ´Î¿Ï…Î¼Îµ ÎµÏ€Î¹ÏƒÎ·Ï‚ ÏŒÏ„Î¹ ÏƒÏ„Î± Ï€ÏÏ‰Ï„Î± epochs Î¿Î¹ Ï„Î¹Î¼ÎµÏ‚ Ï„Ï‰Î½ Î¼ÎµÏ„ÏÎ¹ÎºÏ‰Î½ ÎµÎ¹Î½Î±Î¹ Î±ÏÎºÎµÏ„Î± Ï‡ÎµÎ¹ÏÎ¿ÏŒÏ„ÎµÏÎµÏ‚ ÏƒÎµ ÏƒÏ‡Î­ÏƒÎ· Î¼Îµ Ï€ÏÎ¹Î½.\n"
      ],
      "metadata": {
        "id": "nv6qb1Gwsz1D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Optimizer: Adam** \n",
        "### Î¤Î¹ Ï€Î±ÏÎ±Ï„Î·ÏÎµÎ¯Ï„Îµ Î³Î¹Î± Ï„Î·Î½ ÎµÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ· Ï„Î¿Ï… Î´Î¹ÎºÏ„ÏÎ¿Ï…;\n",
        "\n",
        "Î‘Ï€Î¬Î½Ï„Î·ÏƒÎ·: ÎˆÏ‡Î¿Î½Ï„Î±Ï‚ ÎµÏ†Î±ÏÎ¼ÏŒÏƒÎµÎ¹ Ï‰Ï‚ Adam optimizer Î±Î½Ï„Î¹ Î³Î¹Î± SGD Ï€Î±ÏÎ±Ï„Î·ÏÎ¿ÏÎ¼Îµ, Î¼Îµ Î²Î¬ÏƒÎ· Ï„Î¹Ï‚ Ï„Î¹Î¼ÎµÏ‚ Ï„Ï‰Î½ Î¼ÎµÏ„ÏÎ¹ÎºÏ‰Î½, ÏŒÏ„Î¹ Î· ÎµÎºÏ€Î±Î¹Î´ÎµÏ…ÏƒÎ· Ï„Î¿Ï… Î´Î¹ÎºÏ„ÏÎ¿Ï… Î²ÎµÎ»Ï„Î¹ÏÎ¸Î·ÎºÎµ Î±ÏÎºÎµÏ„Î¬ ÎºÎ±Î¸ÏÏ‚ Î¿Î¹ Ï„Î¹Î¼ÎµÏ‚ ÎºÎ±Î¹ Ï„Ï‰Î½ Ï„ÏÎµÎ¹Ï‰Î½ Î¼ÎµÏ„ÏÎ¹ÎºÏ‰Î½ Î±Ï€ÏŒ epoch ÏƒÎµ epoch Î²ÎµÎ»Ï„Î¹ÏÎ½Î¿Î½Ï„Î±Î¹ ÏÎ±Î³Î´Î±Î¹Î± Î¼Îµ Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î± Î½Î± Î­Ï‡Î¿Ï…Î¼Îµ ÏƒÏ„Î¿ Ï„ÎµÎ»Î¿Ï‚ **Train Loss: 0.009197, Avg loss: 0.007105 ÎºÎ±Î¹ R2 Score: 0.6616853195249721** Ï€Î¿Ï… ÎµÎ¯Î½Î±Î¹ Î¼Î¹Î± Î±ÏÎºÎµÏ„Î± ÎºÎ±Î»Î® Ï„Î¹Î¼Î® Ï€Î¬Î½Ï‰ Î±Ï€Î¿ Ï„Î¿ 0.5 Ï€Î¿Ï… Ï€Î»Î·ÏƒÎ¹Î¬Î¶ÎµÎ¹ Ï„Î¿ 1."
      ],
      "metadata": {
        "id": "sCUkCQn0s8b5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. ÎÎµÏ…ÏÏ‰Î½Î¹ÎºÏŒ Î´Î¯ÎºÏ„Ï…Î¿"
      ],
      "metadata": {
        "id": "08tb4Oe7pZX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ÎšÏÎ´Î¹ÎºÎ±Ï‚ Î¿ÏÎ¹ÏƒÎ¼Î¿Ï Ï„Î¿Ï… Î´Î¹ÎºÏ„ÏÎ¿Ï…\n",
        "class NeuralNetwork2(nn.Module):\n",
        "  def __init__(self):\n",
        "    # Î¤ÏÎ­Ï‡Ï‰ Ï„Î·Î½ init Ï„Î·Ï‚ ÎºÎ»Î¬ÏƒÎ·Ï‚-Î³Î¿Î½Î¹Î¿Ï\n",
        "    super(NeuralNetwork2, self).__init__()\n",
        "    \n",
        "    #Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Ï Î¼Î¹Î± Î±ÏÏ‡Î¹Ï„ÎµÎºÏ„Î¿Î½Î¹ÎºÎ® Ï€Î¿Ï… Î¸Î± Î±Ï€Î¿Ï„ÎµÎ»ÎµÎ¯Ï„Î±Î¹ Î±Ï€Î¿ÎºÎ»ÎµÎ¹ÏƒÏ„Î¹ÎºÎ¬ Î±Ï€ÏŒ Î­Î½Î±Î½ Î½ÎµÏ…ÏÏÎ½Î± Î¼Îµ Î³ÏÎ±Î¼Î¼Î¹ÎºÎ® ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ· ÎµÎ½ÎµÏÎ³Î¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚.\n",
        "    self.network_architecture = nn.Sequential(\n",
        "        nn.Linear(8, 100),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(100, 100),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(100, 1),\n",
        "        #Î· Î­Î¾Î¿Î´Î¿Ï‚ Ï„Î¿Ï… Î´Î¹ÎºÏ„ÏÎ¿Ï… ÎµÎ¯Î½Î±Î¹ Î¼Î· Î³ÏÎ±Î¼Î¼Î¹ÎºÎ® ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ· Ï„Ï‰Î½ Î±ÏÏ‡Î¹ÎºÏ‰Î½ ÎµÎ¹ÏƒÏŒÎ´Ï‰Î½ (Ï„Î¿Ï… Î´Î¹ÎºÏ„ÏÎ¿Ï…), ÎºÎ±Î¸ÏÏ‚ ÏŒÎ»Î¿Î¹ Î¿Î¹ ÎºÏÏ…Ï†Î¿Î¯ Î½ÎµÏ…ÏÏÎ½ÎµÏ‚ Î­Ï‡Î¿Ï…Î½ Î¼Î· Î³ÏÎ±Î¼Î¼Î¹ÎºÎ® ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ· ÎµÎ½ÎµÏÎ³Î¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚ (ReLU).\n",
        "\n",
        "    )\n",
        "    \n",
        "  def forward(self, x):\n",
        "    logits = self.network_architecture(x)\n",
        "    return logits"
      ],
      "metadata": {
        "id": "bwBWbnN_pcTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ÎŸÏÎ¹ÏƒÎ¼ÏŒÏ‚ Ï…Ï€ÎµÏÏ€Î±ÏÎ±Î¼Î­Ï„ÏÏ‰Î½ ÎºÎ±Î¹ ÎµÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ· Î´Î¹ÎºÏ„ÏÎ¿Ï…"
      ],
      "metadata": {
        "id": "Pf4ct2ZFdBSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(50)\n",
        "\n",
        "model = NeuralNetwork2()\n",
        "learning_rate = 0.001\n",
        "epochs = 3000\n",
        "\n",
        "optimizer2 = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "#optimizer2 = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# ÎšÏÎ´Î¹ÎºÎ±Ï‚ ÎµÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·Ï‚ ÎµÎ´Ï:\n",
        "for t in range(epochs):\n",
        "    if t % 100 == 0:\n",
        "      print(f\"Epoch {t}\\n-------------------------------\")\n",
        "    train_loop(train_dataloader, model, loss_fn, optimizer2, t)\n",
        "    if t % 100 == 0:\n",
        "      test_loop(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "id": "JtnT1_vcteiQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea672bb7-0817-4a15-ead3-cc1d4c9889eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n",
            "-------------------------------\n",
            "loss: 0.382369  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -19.83784899013452 , Avg loss: 0.437636 \n",
            "\n",
            "Epoch 100\n",
            "-------------------------------\n",
            "loss: 0.088239  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -3.925405634362586 , Avg loss: 0.103443 \n",
            "\n",
            "Epoch 200\n",
            "-------------------------------\n",
            "loss: 0.029093  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: -0.4570168839710582 , Avg loss: 0.030600 \n",
            "\n",
            "Epoch 300\n",
            "-------------------------------\n",
            "loss: 0.018007  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.30938529505681456 , Avg loss: 0.014504 \n",
            "\n",
            "Epoch 400\n",
            "-------------------------------\n",
            "loss: 0.016027  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.49129072559192677 , Avg loss: 0.010684 \n",
            "\n",
            "Epoch 500\n",
            "-------------------------------\n",
            "loss: 0.015555  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.5452724837616237 , Avg loss: 0.009550 \n",
            "\n",
            "Epoch 600\n",
            "-------------------------------\n",
            "loss: 0.015322  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.5669194103016943 , Avg loss: 0.009096 \n",
            "\n",
            "Epoch 700\n",
            "-------------------------------\n",
            "loss: 0.015133  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.5787266421931179 , Avg loss: 0.008848 \n",
            "\n",
            "Epoch 800\n",
            "-------------------------------\n",
            "loss: 0.014957  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.5870483831749347 , Avg loss: 0.008673 \n",
            "\n",
            "Epoch 900\n",
            "-------------------------------\n",
            "loss: 0.014792  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.5937157360919316 , Avg loss: 0.008533 \n",
            "\n",
            "Epoch 1000\n",
            "-------------------------------\n",
            "loss: 0.014635  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.5994858160264378 , Avg loss: 0.008412 \n",
            "\n",
            "Epoch 1100\n",
            "-------------------------------\n",
            "loss: 0.014486  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.6047993694534383 , Avg loss: 0.008300 \n",
            "\n",
            "Epoch 1200\n",
            "-------------------------------\n",
            "loss: 0.014346  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.6096995779812597 , Avg loss: 0.008197 \n",
            "\n",
            "Epoch 1300\n",
            "-------------------------------\n",
            "loss: 0.014214  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.6142009402292019 , Avg loss: 0.008103 \n",
            "\n",
            "Epoch 1400\n",
            "-------------------------------\n",
            "loss: 0.014091  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.6181909454905874 , Avg loss: 0.008019 \n",
            "\n",
            "Epoch 1500\n",
            "-------------------------------\n",
            "loss: 0.013977  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.6218807747257258 , Avg loss: 0.007941 \n",
            "\n",
            "Epoch 1600\n",
            "-------------------------------\n",
            "loss: 0.013872  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.6253171684078966 , Avg loss: 0.007869 \n",
            "\n",
            "Epoch 1700\n",
            "-------------------------------\n",
            "loss: 0.013772  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.6284389069255798 , Avg loss: 0.007804 \n",
            "\n",
            "Epoch 1800\n",
            "-------------------------------\n",
            "loss: 0.013675  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.6313469369987248 , Avg loss: 0.007742 \n",
            "\n",
            "Epoch 1900\n",
            "-------------------------------\n",
            "loss: 0.013582  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.6341333718225107 , Avg loss: 0.007684 \n",
            "\n",
            "Epoch 2000\n",
            "-------------------------------\n",
            "loss: 0.013493  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.6368673144101931 , Avg loss: 0.007627 \n",
            "\n",
            "Epoch 2100\n",
            "-------------------------------\n",
            "loss: 0.013407  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.6394834590885363 , Avg loss: 0.007572 \n",
            "\n",
            "Epoch 2200\n",
            "-------------------------------\n",
            "loss: 0.013323  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.6420082619724321 , Avg loss: 0.007519 \n",
            "\n",
            "Epoch 2300\n",
            "-------------------------------\n",
            "loss: 0.013244  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.6443748183140665 , Avg loss: 0.007469 \n",
            "\n",
            "Epoch 2400\n",
            "-------------------------------\n",
            "loss: 0.013168  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.6466500239761146 , Avg loss: 0.007421 \n",
            "\n",
            "Epoch 2500\n",
            "-------------------------------\n",
            "loss: 0.013095  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.6488095225905575 , Avg loss: 0.007376 \n",
            "\n",
            "Epoch 2600\n",
            "-------------------------------\n",
            "loss: 0.013026  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.6508614885235702 , Avg loss: 0.007333 \n",
            "\n",
            "Epoch 2700\n",
            "-------------------------------\n",
            "loss: 0.012959  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.6527914537789092 , Avg loss: 0.007292 \n",
            "\n",
            "Epoch 2800\n",
            "-------------------------------\n",
            "loss: 0.012896  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.6545959373064595 , Avg loss: 0.007254 \n",
            "\n",
            "Epoch 2900\n",
            "-------------------------------\n",
            "loss: 0.012835  [  250/  250]\n",
            "Test Error: \n",
            " R2 Score: 0.6563155584689719 , Avg loss: 0.007218 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Î¤Î¹ Ï€Î±ÏÎ±Ï„Î·ÏÎµÎ¯Ï„Îµ ÏƒÎµ ÏƒÏ‡Î­ÏƒÎ· Î¼Îµ Ï„Î·Î½ Ï„Î±Ï‡ÏÏ„Î·Ï„Î± ÎµÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·Ï‚, ÎºÎ±Î¹ Ï„Î¹Ï‚ Ï„Î¹Î¼Î­Ï‚ Ï„Ï‰Î½ ÎºÏÎ¹Ï„Î·ÏÎ¯Ï‰Î½ Î±Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ·Ï‚ ÏƒÏ„Î¿ Ï‡ÏÏŒÎ½Î¿;\n",
        "\n",
        "ÎœÎµ Optimizer:\n",
        "\n",
        "> **SGD**: Î Î±ÏÎ±Ï„Î·ÏÎ¿ÏÎ¼Îµ ÏŒÏ„Î¹ Î· Ï„Î±Ï‡ÏÏ„Î·Ï„Î± ÎµÎºÏ€Î¬Î¹Î´ÎµÏ…ÏƒÎ·Ï‚ Ï„Î¿Ï… Î´Î¹ÎºÏ„ÏÎ¿Ï… ÎµÎ¹Î½Î±Î¹ Î±ÏÎºÎµÏ„Î± Ï…ÏˆÎ·Î»Î·Ï‚ ÏƒÎµ ÏƒÏ‡ÎµÏƒÎ· Î¼Îµ Ï€ÏÎ¹Î½ (Î²Î» 2. ÎœÎµÎ¼Î¿Î½Ï‰Î¼Î­Î½Î¿Ï‚ Î½ÎµÏ…ÏÏÎ½Î±Ï‚) ÎºÎ±Î¹ Î±Ï…Ï„Î¿ ÎµÎ¹Î½Î±Î¹ ÎµÎ¼Ï†Î±Î½ÎµÏ‚ Î±Ï€Î¿ Ï„Î¹Ï‚ Ï‡Î±Î¼Î·Î»ÎµÏ‚ Ï„Î¹Î¼ÎµÏ‚ Ï„Ï‰Î½ ÎºÏÎ¹Ï„Î·ÏÎ¯Ï‰Î½ Î±Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ·Ï‚ (Train/Test Loss) Î±Ï€Î¿ Ï„Î¿ Ï€ÏÏ‰Ï„Î¿ ÎºÎ¹Î¿Î»Î±Ï‚ epoch ÎºÎ±Î¹ ÎºÎ±Î¸Ï‰Ï‚ Ï€ÏÎ¿Ï‡Ï‰ÏÎ±Î¼Îµ Î±Ï€Î¿ epoch ÏƒÎµ epoch. ÎœÏ€Î¿ÏÎµÎ¹ ÎµÏ€Î¹Ï€Î»ÎµÎ¿Î½ Î½Î± Ï€Î±ÏÎ±Ï„Î·ÏÎ·ÏƒÎµÎ¹ ÎºÎ±Î½ÎµÎ¹Ï‚ Î¿Ï„Î¹ Î· Ï…ÏˆÎ·Î»Î· Ï„Î±Ï‡Ï…Ï„Î·Ï„Î± ÎµÎºÏ€Î±Î¹Î´ÎµÏ…ÏƒÎ·Ï‚ ÎµÎ¹Î½Î±Î¹ Î¹Î´Î¹Î±Î¹Ï„ÎµÏÎ± ÎµÎ¼Ï†Î±Î½Î·Ï‚ ÏƒÏ„Î± Ï€ÏÏ‰Ï„Î± 500 epoch. Î•Ï€Î¹Ï€Î»ÎµÏŒÎ½ Î¿Î¹ Ï„Î¹Î¼ÎµÏ‚ Ï„Ï‰Î½ ÎºÏÎ¹Ï„Î·ÏÎ¹Ï‰Î½ Î±Î¾Î¹Î¿Î»Î¿Î³Î·ÏƒÎ·Ï‚, **Train ÎºÎ±Î¹ Test Loss**, ÎµÎ¯Î½Î±Î¹ ÎºÎ±Î»Ï…Ï„ÎµÏÎµÏ‚ ÏƒÎµ ÏƒÏ‡ÎµÏƒÎ· Î¼Îµ Ï€ÏÎ¹Î½, **0.012835 ÎºÎ±Î¹ 0.007218** Î±Î½Ï„Î¹ÏƒÏ„Î¿Î¹Ï‡Î±. Î· Ï„Î¹Î¼Î· Ï„Î¿Ï… **R2 Score** ÎµÎ¹Î½Î±Î¹ Î±ÏÎºÎµÏ„Î± Ï€Î¹Î¿ Ï…ÏˆÎ·Î»Î· (**0.6563155584689719**) ÏƒÎµ ÏƒÏ‡ÎµÏƒÎ· Î¼Îµ Ï„Î·Î½ *Ï€ÏÎ¿Î·Î³Î¿Ï…Î¼ÎµÎ½Î· Ï„Î¹Î¼Î® (0.09256793853624656).*\n",
        "\n",
        "\n",
        "> **Adam**: Î Î±ÏÎ±Ï„Î·ÏÎ¿Ï…Î¼Îµ ÏŒÏ„Î¹ Î¿Ï€Ï‰Ï‚ ÎºÎ±Î¹ Î¼Îµ Ï„Î¿Î½ SGD Î· Ï„Î±Ï‡Ï…Ï„Î·Ï„Î± ÎµÎ¹Î½Î±Î¹ Î±ÏÎºÎµÏ„Î± Ï…ÏˆÎ·Î»Î·Ï‚ ÏƒÎµ ÏƒÏ‡ÎµÏƒÎ· Î¼Îµ Ï€ÏÎ¹Î½ ÎºÎ±Î¸Ï‰Ï‚ ÎºÎ±Î¹ ÏŒÏƒÎ¿ Ï€ÎµÏÎ½Î±ÎµÎ¹ Î¿ Ï‡ÏÎ¿Î½Î¿Ï‚ Î¿Î¹ Ï„Î¹Î¼ÎµÏ‚ Ï„Ï‰Î½ ÎºÏÎ¹Ï„Î·ÏÎ¯Ï‰Î½ Î±Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ·Ï‚ Î±Ï…Î¾Î¿Î¼ÎµÎ¹Ï‰Î½Î¿Î½Ï„Î±Î¹ ÏƒÏ…Î½ÎµÏ‡Ï‰Ï‚. Î•Ï€Î¹Ï€Î»Î­Î¿Î½, Ï€Î±ÏÎ±Ï„Î·ÏÎ¿Ï…Î¼Îµ Î¿Ï„Î¹ Î¼Îµ Ï„Î¿Î½ Adam Optimizer, Î¿Î¹ Ï„Î¹Î¼ÎµÏ‚ Ï„Ï‰Î½ ÎºÏÎ¹Ï„Î·ÏÎ¯Ï‰Î½ Î±Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ·Ï‚ Î³Î½Ï‰ÏÎ¯Î¶Î¿Ï…Î½ ÏÎ±Î³Î´Î±Î¹Î± Î²ÎµÎ»Ï„Î¯Ï‰ÏƒÎ· ÏƒÏ„Î± Ï€ÏÏ‰Ï„Î± 100 epochs. ÎŒÎ¼Ï‰Ï‚, Ï€Î±ÏÎ±Ï„Î·ÏÎ·Î¸Î·ÎºÎµ ÏŒÏ„Î¹ ÎµÎ½Ï‰ Î±ÏÏ‡Î¹ÎºÎ± Î¿Î¹ Ï„Î¹Î¼Î® Ï„Î¿Ï… **R2 Score** ÎµÎ¹Î½Î±Î¹ Î±ÏÎºÎµÏ„Î± ÎºÎ±Î»Î® (*0.7615950507301525*) ÏƒÏ„Î·Î½ ÏƒÏ…Î½ÎµÏ‡ÎµÎ¹Î± Î¿ÏƒÎ¿ Ï€ÎµÏÎ½Î±Î½Îµ Ï„Î± epochs Î· Ï„Î¹Î¼Î· Ï„Î·Ï‚ Ï‡ÎµÎ¹ÏÎ¿Ï„ÎµÏÎµÏ…ÎµÎ¹ Ï‰ÏƒÏ€Î¿Ï… Î½Î± ÎºÎ±Ï„Î±Î»Î·Î¾ÎµÎ¹ ÏƒÏ„Î¿ **0.6858477112869089**.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9VmWP-O1__jV"
      }
    }
  ]
}